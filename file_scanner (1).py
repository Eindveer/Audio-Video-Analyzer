# -*- coding: utf-8 -*-
"""File Scanner

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b7ewkmQdK1j2icTadCit0DrjvEtHJmf1
"""

!pip install -q openai-whisper transformers librosa pandas openpyxl moviepy \
  keybert rake-nltk spacy pyannote.audio torch torchvision torchaudio \
  accelerate

import nltk
nltk.download('stopwords')

!python -m spacy download en_core_web_sm

from google.colab import files
uploaded = files.upload()
file_path = next(iter(uploaded))

from moviepy.editor import VideoFileClip
import os

def extract_audio(file_path):
    if file_path.lower().endswith(('.mp4', '.mov', '.mkv', '.avi')):
        clip = VideoFileClip(file_path)
        audio_path = "extracted_audio.wav"
        clip.audio.write_audiofile(audio_path)
        return audio_path
    return file_path

audio_file = extract_audio(file_path)

import whisper

model = whisper.load_model("tiny")
result = model.transcribe(audio_file, task="transcribe")
transcript = result["text"]
segments = result["segments"]

from transformers import pipeline

summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

def summarize_text(text, max_chunk=500):
    sentences = text.split(". ")
    chunks, chunk = [], ""
    for sentence in sentences:
        if len(chunk) + len(sentence) <= max_chunk:
            chunk += sentence + ". "
        else:
            chunks.append(chunk.strip())
            chunk = sentence + ". "
    chunks.append(chunk.strip())
    summary = ""
    for chunk in chunks:
        summary += summarizer(chunk, max_length=100, min_length=30, do_sample=False)[0]['summary_text'] + " "
    return summary.strip()

summary = summarize_text(transcript)

from keybert import KeyBERT
kw_model = KeyBERT()
keywords = kw_model.extract_keywords(transcript, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=10)
keywords = [kw[0] for kw in keywords]

from pyannote.audio import Pipeline

pipeline = Pipeline.from_pretrained(
    "pyannote/speaker-diarization",
    use_auth_token="hugging face key"
)

diarization = pipeline(audio_file)

for turn, _, speaker in diarization.itertracks(yield_label=True):
    print(f"{turn.start:.1f}s - {turn.end:.1f}s: {speaker}")

print("Timestamped Segments:")
for seg in segments:
    print(f"{seg['start']:.2f}s - {seg['end']:.2f}s: {seg['text']}")

import spacy
nlp = spacy.load("en_core_web_sm")
doc = nlp(transcript)

named_entities = [(ent.text, ent.label_) for ent in doc.ents]

from transformers import pipeline

emotion_model = pipeline("text-classification", model="nateraw/bert-base-uncased-emotion")
emotions = emotion_model(transcript[:512])

import pandas as pd


with open("summary.txt", "w") as f:
    f.write(summary)


df = pd.DataFrame({
    "Top Keywords": [", ".join(keywords)],
    "Named Entities": [", ".join([e[0] for e in named_entities])],
    "Emotions": [", ".join([f"{e['label']} ({e['score']:.2f})" for e in emotions])]
})

df.to_excel("analysis_report.xlsx", index=False)


files.download("summary.txt")
files.download("analysis_report.xlsx")